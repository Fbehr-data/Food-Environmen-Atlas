{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline model notebook\n",
    "*by Max*\n",
    "\n",
    "In this notebook I'll attempt to create a simple baseline model with the Scikit-Learn DummyClassifier for our already feature engineered data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the modules, set the working directories and load the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the needed modules\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# import own modules from the scr folder\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from src.find_repo_root import get_repo_root\n",
    "\n",
    "# Set a random seed\n",
    "RSEED = 42\n",
    "np.random.seed(RSEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the directory of the data \n",
    "ROOT_DIR = get_repo_root()\n",
    "DATA_DIR = f\"{ROOT_DIR}/data\"\n",
    "# Load the base data from the CSV files\n",
    "df_train = pd.read_csv(f'{DATA_DIR}/Train_Dataset4.csv')\n",
    "df_test = pd.read_csv(f'{DATA_DIR}/Test_Dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>B02_10</th>\n",
       "      <th>B02_11</th>\n",
       "      <th>B02_5</th>\n",
       "      <th>B02_6</th>\n",
       "      <th>B02_7</th>\n",
       "      <th>B02_8</th>\n",
       "      <th>B02_9</th>\n",
       "      <th>SIPI2_10</th>\n",
       "      <th>SIPI2_11</th>\n",
       "      <th>SIPI2_5</th>\n",
       "      <th>...</th>\n",
       "      <th>B12_11</th>\n",
       "      <th>B12_5</th>\n",
       "      <th>B12_6</th>\n",
       "      <th>B12_7</th>\n",
       "      <th>B12_8</th>\n",
       "      <th>B12_9</th>\n",
       "      <th>field_id</th>\n",
       "      <th>field_size</th>\n",
       "      <th>tile_id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.579470</td>\n",
       "      <td>26.362030</td>\n",
       "      <td>25.397352</td>\n",
       "      <td>18.781458</td>\n",
       "      <td>13.030905</td>\n",
       "      <td>12.876821</td>\n",
       "      <td>13.313466</td>\n",
       "      <td>-0.245756</td>\n",
       "      <td>-0.912282</td>\n",
       "      <td>-1.186115</td>\n",
       "      <td>...</td>\n",
       "      <td>83.796910</td>\n",
       "      <td>92.823400</td>\n",
       "      <td>48.430460</td>\n",
       "      <td>39.593819</td>\n",
       "      <td>35.895364</td>\n",
       "      <td>32.980132</td>\n",
       "      <td>4</td>\n",
       "      <td>151</td>\n",
       "      <td>2526</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15.625155</td>\n",
       "      <td>30.736414</td>\n",
       "      <td>20.636646</td>\n",
       "      <td>14.451087</td>\n",
       "      <td>12.849896</td>\n",
       "      <td>12.036879</td>\n",
       "      <td>10.022516</td>\n",
       "      <td>-0.368229</td>\n",
       "      <td>-1.585534</td>\n",
       "      <td>-2.862939</td>\n",
       "      <td>...</td>\n",
       "      <td>86.229038</td>\n",
       "      <td>80.363353</td>\n",
       "      <td>57.829969</td>\n",
       "      <td>48.347308</td>\n",
       "      <td>48.054347</td>\n",
       "      <td>41.500000</td>\n",
       "      <td>14</td>\n",
       "      <td>644</td>\n",
       "      <td>979</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>39.258299</td>\n",
       "      <td>40.167746</td>\n",
       "      <td>34.846287</td>\n",
       "      <td>34.478986</td>\n",
       "      <td>32.261831</td>\n",
       "      <td>25.978018</td>\n",
       "      <td>32.592746</td>\n",
       "      <td>-1.813169</td>\n",
       "      <td>-1.902605</td>\n",
       "      <td>-2.430946</td>\n",
       "      <td>...</td>\n",
       "      <td>128.347796</td>\n",
       "      <td>112.936530</td>\n",
       "      <td>106.362693</td>\n",
       "      <td>104.270466</td>\n",
       "      <td>78.176480</td>\n",
       "      <td>111.094649</td>\n",
       "      <td>20</td>\n",
       "      <td>579</td>\n",
       "      <td>632</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30.529762</td>\n",
       "      <td>31.458333</td>\n",
       "      <td>21.476191</td>\n",
       "      <td>23.166666</td>\n",
       "      <td>21.714286</td>\n",
       "      <td>36.603175</td>\n",
       "      <td>28.380952</td>\n",
       "      <td>-1.469586</td>\n",
       "      <td>-1.584824</td>\n",
       "      <td>-1.774970</td>\n",
       "      <td>...</td>\n",
       "      <td>91.327380</td>\n",
       "      <td>59.317463</td>\n",
       "      <td>71.357140</td>\n",
       "      <td>60.195237</td>\n",
       "      <td>71.809521</td>\n",
       "      <td>82.873017</td>\n",
       "      <td>25</td>\n",
       "      <td>42</td>\n",
       "      <td>1779</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24.042105</td>\n",
       "      <td>31.447369</td>\n",
       "      <td>20.434211</td>\n",
       "      <td>11.144737</td>\n",
       "      <td>15.122807</td>\n",
       "      <td>14.789474</td>\n",
       "      <td>23.780702</td>\n",
       "      <td>-0.628406</td>\n",
       "      <td>-0.767568</td>\n",
       "      <td>-0.581649</td>\n",
       "      <td>...</td>\n",
       "      <td>92.263160</td>\n",
       "      <td>78.157895</td>\n",
       "      <td>36.763160</td>\n",
       "      <td>110.824563</td>\n",
       "      <td>49.315791</td>\n",
       "      <td>95.947369</td>\n",
       "      <td>40</td>\n",
       "      <td>38</td>\n",
       "      <td>229</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44579</th>\n",
       "      <td>28.799311</td>\n",
       "      <td>26.082687</td>\n",
       "      <td>21.297674</td>\n",
       "      <td>16.379845</td>\n",
       "      <td>18.810077</td>\n",
       "      <td>19.219638</td>\n",
       "      <td>16.693023</td>\n",
       "      <td>-0.950567</td>\n",
       "      <td>-1.343456</td>\n",
       "      <td>-1.480490</td>\n",
       "      <td>...</td>\n",
       "      <td>112.692507</td>\n",
       "      <td>97.497676</td>\n",
       "      <td>60.635660</td>\n",
       "      <td>75.328490</td>\n",
       "      <td>65.951766</td>\n",
       "      <td>59.686821</td>\n",
       "      <td>122575</td>\n",
       "      <td>129</td>\n",
       "      <td>328</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44580</th>\n",
       "      <td>39.166309</td>\n",
       "      <td>41.524606</td>\n",
       "      <td>25.985279</td>\n",
       "      <td>21.685804</td>\n",
       "      <td>30.242208</td>\n",
       "      <td>31.908202</td>\n",
       "      <td>34.830126</td>\n",
       "      <td>-2.682721</td>\n",
       "      <td>-2.840744</td>\n",
       "      <td>-3.085017</td>\n",
       "      <td>...</td>\n",
       "      <td>123.411594</td>\n",
       "      <td>89.736696</td>\n",
       "      <td>86.639120</td>\n",
       "      <td>105.163785</td>\n",
       "      <td>105.319322</td>\n",
       "      <td>114.508834</td>\n",
       "      <td>122598</td>\n",
       "      <td>1585</td>\n",
       "      <td>1866</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44581</th>\n",
       "      <td>21.843733</td>\n",
       "      <td>27.097631</td>\n",
       "      <td>18.036413</td>\n",
       "      <td>16.225464</td>\n",
       "      <td>14.694922</td>\n",
       "      <td>13.036437</td>\n",
       "      <td>19.139924</td>\n",
       "      <td>-1.712284</td>\n",
       "      <td>-1.934333</td>\n",
       "      <td>-2.280996</td>\n",
       "      <td>...</td>\n",
       "      <td>117.154356</td>\n",
       "      <td>94.620421</td>\n",
       "      <td>83.251935</td>\n",
       "      <td>77.238681</td>\n",
       "      <td>61.385198</td>\n",
       "      <td>91.039976</td>\n",
       "      <td>122628</td>\n",
       "      <td>1851</td>\n",
       "      <td>1289</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44582</th>\n",
       "      <td>29.212181</td>\n",
       "      <td>31.240177</td>\n",
       "      <td>24.055010</td>\n",
       "      <td>21.530452</td>\n",
       "      <td>28.157171</td>\n",
       "      <td>15.517191</td>\n",
       "      <td>25.599869</td>\n",
       "      <td>-1.173500</td>\n",
       "      <td>-1.536702</td>\n",
       "      <td>-2.042598</td>\n",
       "      <td>...</td>\n",
       "      <td>107.960216</td>\n",
       "      <td>80.254092</td>\n",
       "      <td>71.731829</td>\n",
       "      <td>74.854123</td>\n",
       "      <td>47.880157</td>\n",
       "      <td>92.817945</td>\n",
       "      <td>122662</td>\n",
       "      <td>509</td>\n",
       "      <td>2434</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44583</th>\n",
       "      <td>12.368787</td>\n",
       "      <td>16.113652</td>\n",
       "      <td>14.674454</td>\n",
       "      <td>8.470179</td>\n",
       "      <td>8.977137</td>\n",
       "      <td>8.065358</td>\n",
       "      <td>9.516236</td>\n",
       "      <td>-0.213081</td>\n",
       "      <td>-0.371929</td>\n",
       "      <td>-0.523603</td>\n",
       "      <td>...</td>\n",
       "      <td>56.021206</td>\n",
       "      <td>59.869782</td>\n",
       "      <td>33.305170</td>\n",
       "      <td>32.897283</td>\n",
       "      <td>31.789762</td>\n",
       "      <td>31.371107</td>\n",
       "      <td>122704</td>\n",
       "      <td>1006</td>\n",
       "      <td>488</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>44584 rows × 144 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          B02_10     B02_11      B02_5      B02_6      B02_7      B02_8  \\\n",
       "0      17.579470  26.362030  25.397352  18.781458  13.030905  12.876821   \n",
       "1      15.625155  30.736414  20.636646  14.451087  12.849896  12.036879   \n",
       "2      39.258299  40.167746  34.846287  34.478986  32.261831  25.978018   \n",
       "3      30.529762  31.458333  21.476191  23.166666  21.714286  36.603175   \n",
       "4      24.042105  31.447369  20.434211  11.144737  15.122807  14.789474   \n",
       "...          ...        ...        ...        ...        ...        ...   \n",
       "44579  28.799311  26.082687  21.297674  16.379845  18.810077  19.219638   \n",
       "44580  39.166309  41.524606  25.985279  21.685804  30.242208  31.908202   \n",
       "44581  21.843733  27.097631  18.036413  16.225464  14.694922  13.036437   \n",
       "44582  29.212181  31.240177  24.055010  21.530452  28.157171  15.517191   \n",
       "44583  12.368787  16.113652  14.674454   8.470179   8.977137   8.065358   \n",
       "\n",
       "           B02_9  SIPI2_10  SIPI2_11   SIPI2_5  ...      B12_11       B12_5  \\\n",
       "0      13.313466 -0.245756 -0.912282 -1.186115  ...   83.796910   92.823400   \n",
       "1      10.022516 -0.368229 -1.585534 -2.862939  ...   86.229038   80.363353   \n",
       "2      32.592746 -1.813169 -1.902605 -2.430946  ...  128.347796  112.936530   \n",
       "3      28.380952 -1.469586 -1.584824 -1.774970  ...   91.327380   59.317463   \n",
       "4      23.780702 -0.628406 -0.767568 -0.581649  ...   92.263160   78.157895   \n",
       "...          ...       ...       ...       ...  ...         ...         ...   \n",
       "44579  16.693023 -0.950567 -1.343456 -1.480490  ...  112.692507   97.497676   \n",
       "44580  34.830126 -2.682721 -2.840744 -3.085017  ...  123.411594   89.736696   \n",
       "44581  19.139924 -1.712284 -1.934333 -2.280996  ...  117.154356   94.620421   \n",
       "44582  25.599869 -1.173500 -1.536702 -2.042598  ...  107.960216   80.254092   \n",
       "44583   9.516236 -0.213081 -0.371929 -0.523603  ...   56.021206   59.869782   \n",
       "\n",
       "            B12_6       B12_7       B12_8       B12_9  field_id  field_size  \\\n",
       "0       48.430460   39.593819   35.895364   32.980132         4         151   \n",
       "1       57.829969   48.347308   48.054347   41.500000        14         644   \n",
       "2      106.362693  104.270466   78.176480  111.094649        20         579   \n",
       "3       71.357140   60.195237   71.809521   82.873017        25          42   \n",
       "4       36.763160  110.824563   49.315791   95.947369        40          38   \n",
       "...           ...         ...         ...         ...       ...         ...   \n",
       "44579   60.635660   75.328490   65.951766   59.686821    122575         129   \n",
       "44580   86.639120  105.163785  105.319322  114.508834    122598        1585   \n",
       "44581   83.251935   77.238681   61.385198   91.039976    122628        1851   \n",
       "44582   71.731829   74.854123   47.880157   92.817945    122662         509   \n",
       "44583   33.305170   32.897283   31.789762   31.371107    122704        1006   \n",
       "\n",
       "       tile_id  label  \n",
       "0         2526      8  \n",
       "1          979      8  \n",
       "2          632      8  \n",
       "3         1779      3  \n",
       "4          229      3  \n",
       "...        ...    ...  \n",
       "44579      328      5  \n",
       "44580     1866      5  \n",
       "44581     1289      5  \n",
       "44582     2434      5  \n",
       "44583      488      5  \n",
       "\n",
       "[44584 rows x 144 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8, 3, 1, 2, 4, 6, 7, 5])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.label.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Model\n",
    "\n",
    "For this baseline model, we use the mean bands for each field as well as the mean of a few selected spectral indices. For the model we go with the very simple DummyClassifier, in order to give us an idea where the baseline for the other models lies. \n",
    "\n",
    "We chose the F1 score and Accuracy as metrics, since the main goal is to correctly identify as many plants as possible. Neither FP nor FN are particularly bad or good, hence the harmonic mean F1. In addition, we also have an eye on the cross-entropy, because later we will deal with the probabilities with which a class is assigned to a field. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we split the features and the target for test and train data.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get X for the train and validation data\n",
    "X_train = df_train.drop(columns=['label', 'field_id', 'tile_id'])\n",
    "X_test = df_test.drop(columns=['label', 'field_id', 'tile_id'])\n",
    "\n",
    "# Get y for the train and validation data\n",
    "y_train = df_train['label']\n",
    "y_train = y_train.astype(int)\n",
    "y_test = df_test['label']\n",
    "y_test = y_test.astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here the modelling is done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DummyClassifier(random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DummyClassifier</label><div class=\"sk-toggleable__content\"><pre>DummyClassifier(random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DummyClassifier(random_state=42)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "# Fitting the RF model\n",
    "rf = DummyClassifier(random_state = RSEED)\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train = rf.predict(X_train)\n",
    "y_pred_test = rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_proba_train = rf.predict_proba(X_train)\n",
    "y_proba_test = rf.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the results of our Dummy Classifier model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "Accuracy on train data: 0.125\n",
      "Accuracy on test data: 0.094\n",
      "------------------------------------\n",
      "F1-score on train data: 0.028\n",
      "F1-score on test data: 0.022\n",
      "------------------------------------\n",
      "Cross-entropy on train data: 2.079\n",
      "Cross-entropy on test data: 2.079\n",
      "------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, log_loss\n",
    "\n",
    "print('---'*12)\n",
    "print(f'Accuracy on train data: {round(accuracy_score(y_train, y_pred_train), 3)}')\n",
    "print(f'Accuracy on test data: {round(accuracy_score(y_test, y_pred_test), 3)}')\n",
    "print('---'*12)\n",
    "print(f'F1-score on train data: {round(f1_score(y_train, y_pred_train, average=\"macro\"), 3)}')\n",
    "print(f'F1-score on test data: {round(f1_score(y_test, y_pred_test, average=\"macro\"), 3)}')\n",
    "print('---'*12)\n",
    "print(f'Cross-entropy on train data: {round(log_loss(y_train, y_proba_train), 3)}')\n",
    "print(f'Cross-entropy on test data: {round(log_loss(y_test, y_proba_test), 3)}')\n",
    "print('---'*12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the baseline lies really low!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.8 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4f09b4927e4ba45dbad33b3bb266e4177c67ff52e8879550fc4abd145d1e96f6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
