{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required libraries\n",
    "import os\n",
    "import tarfile\n",
    "import json\n",
    "from pathlib import Path\n",
    "from radiant_mlhub.client import _download as download_file\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "os.environ['MLHUB_API_KEY'] = 'N/A'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('./data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DOWNLOAD_S1 = False # If you set this to true then the Sentinel-1 data will be downloaded which is not needed in this notebook.\n",
    "\n",
    "# Select which imagery bands you'd like to download here:\n",
    "DOWNLOAD_BANDS = {\n",
    "    'B01': False,\n",
    "    'B02': True,\n",
    "    'B03': True,\n",
    "    'B04': True,\n",
    "    'B05': False,\n",
    "    'B06': False,\n",
    "    'B07': False,\n",
    "    'B08': True,\n",
    "    'B8A': False,\n",
    "    'B09': False,\n",
    "    'B11': True,\n",
    "    'B12': True,\n",
    "    'CLM': True\n",
    "}\n",
    "\n",
    "# In this model we will only use Green, Red and NIR bands. You can select to download any number of bands. \n",
    "# Our choice relies on the fact that vegetation is most sensitive to these bands. \n",
    "# We also donwload the CLM or Cloud Mask layer to exclude cloudy data from the training phase. \n",
    "# You can also do a feature selection, and try different combination of bands to see which ones will result in a better accuracy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FOLDER_BASE = 'ref_south_africa_crops_competition_v1'\n",
    "\n",
    "def download_archive(archive_name):\n",
    "    if os.path.exists(archive_name.replace('.tar.gz', '')):\n",
    "        return\n",
    "    \n",
    "    print(f'Downloading {archive_name} ...')\n",
    "    download_url = f'https://radiant-mlhub.s3.us-west-2.amazonaws.com/archives/{archive_name}'\n",
    "    download_file(download_url, '.')\n",
    "    print(f'Extracting {archive_name} ...')\n",
    "    with tarfile.open(archive_name) as tfile:\n",
    "        tfile.extractall()\n",
    "    os.remove(archive_name)\n",
    "\n",
    "for split in ['train', 'test']:\n",
    "    # Download the labels\n",
    "    labels_archive = f'{FOLDER_BASE}_{split}_labels.tar.gz'\n",
    "    download_archive(labels_archive)\n",
    "    \n",
    "    # Download Sentinel-1 data\n",
    "    if DOWNLOAD_S1:\n",
    "        s1_archive = f'{FOLDER_BASE}_{split}_source_s1.tar.gz'\n",
    "        download_archive(s1_archive)\n",
    "        \n",
    "\n",
    "    for band, download in DOWNLOAD_BANDS.items():\n",
    "        if not download:\n",
    "            continue\n",
    "        s2_archive = f'{FOLDER_BASE}_{split}_source_s2_{band}.tar.gz'\n",
    "        download_archive(s2_archive)\n",
    "        \n",
    "print('Finished downloading the data!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resolve_path(base, path):\n",
    "    return Path(os.path.join(base, path)).resolve()\n",
    "        \n",
    "def load_df(collection_id):\n",
    "    split = collection_id.split('_')[-2]\n",
    "    collection = json.load(open(f'{collection_id}/collection.json', 'r'))\n",
    "    rows = []\n",
    "    item_links = []\n",
    "    for link in collection['links']:\n",
    "        if link['rel'] != 'item':\n",
    "            continue\n",
    "        item_links.append(link['href'])\n",
    "        \n",
    "    for item_link in item_links:\n",
    "        item_path = f'{collection_id}/{item_link}'\n",
    "        current_path = os.path.dirname(item_path)\n",
    "        item = json.load(open(item_path, 'r'))\n",
    "        tile_id = item['id'].split('_')[-1]\n",
    "        for asset_key, asset in item['assets'].items():\n",
    "            rows.append([\n",
    "                tile_id,\n",
    "                None,\n",
    "                None,\n",
    "                asset_key,\n",
    "                str(resolve_path(current_path, asset['href']))\n",
    "            ])\n",
    "            \n",
    "        for link in item['links']:\n",
    "            if link['rel'] != 'source':\n",
    "                continue\n",
    "            source_item_id = link['href'].split('/')[-2]\n",
    "            \n",
    "            if source_item_id.find('_s1_') > 0 and not DOWNLOAD_S1:\n",
    "                continue\n",
    "            elif source_item_id.find('_s1_') > 0:\n",
    "                for band in ['VV', 'VH']:\n",
    "                    asset_path = Path(f'{FOLDER_BASE}_{split}_source_s1/{source_item_id}/{band}.tif').resolve()\n",
    "                    date = '-'.join(source_item_id.split('_')[10:13])\n",
    "                    \n",
    "                    rows.append([\n",
    "                        tile_id,\n",
    "                        f'{date}T00:00:00Z',\n",
    "                        's1',\n",
    "                        band,\n",
    "                        asset_path\n",
    "                    ])\n",
    "                \n",
    "            if source_item_id.find('_s2_') > 0:\n",
    "                for band, download in DOWNLOAD_BANDS.items():\n",
    "                    if not download:\n",
    "                        continue\n",
    "                    \n",
    "                    asset_path = Path(f'{FOLDER_BASE}_{split}_source_s2_{band}/{source_item_id}_{band}.tif').resolve()\n",
    "                    date = '-'.join(source_item_id.split('_')[10:13])\n",
    "                    rows.append([\n",
    "                        tile_id,\n",
    "                        f'{date}T00:00:00Z',\n",
    "                        's2',\n",
    "                        band,\n",
    "                        asset_path\n",
    "                    ])\n",
    "            \n",
    "    return pd.DataFrame(rows, columns=['tile_id', 'datetime', 'satellite_platform', 'asset', 'file_path'])\n",
    "\n",
    "competition_train_df = load_df('./ref_south_africa_crops_competition_v1_train_labels/')\n",
    "competition_test_df = load_df('./ref_south_africa_crops_competition_v1_test_labels/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "competition_train_df.to_csv('train_data.csv')\n",
    "competition_test_df.to_csv('test_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('../')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.8 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1e3793c75b786e89adf649773953b9416b2a9a325c8c506e782dfcf39e2e2db4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
