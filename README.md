# Radiant Earth Spot the Crop Challenge

In this project we work on the Zindi challenge: ["Radiant Earth Spot the Crop Challenge"](https://zindi.africa/competitions/radiant-earth-spot-the-crop-challenge/data).

The background of the project:

- "The agricultural sector makes a substantial contribution to GDP and livelihoods across the developing world. However, regular and reliable agricultural data remains difficult and expensive to collect on the ground. As a result, policy-makers usually donâ€™t have access to updated data for implementing policies or supporting farmers." 

- "Earth observation satellites provide a wealth of multi-spectral image data that can be used for developing agricultural monitoring tools. These tools support farmers and policy-makers across Africa and the developing world."

- The dataset was generated by the [Radiant Earth Foundation](https://www.radiant.earth/) team, using the ground reference data collected and provided by the Western Cape Department of Agriculture.

The objective of the project:

- The objective of this challenge is therefore to classify crops in the Western Cape of South Africa using time series of Sentinel-2 multi-spectral data. Our goal was to build a machine learning model to predict the crop type classes for dataset. 

---
## The Team

Anitha Grace Uwinema: 
- I studied Water and Environmental Engineering and I am looking into becoming a data scientist.
- Find me on [GitHub](https://github.com/uwinema), [LinkedIn](https://www.linkedin.com/in/anitha-grace-uwinema-17b348240/)

Felix Behrendt:
- I studied Geoinformatics and love to gain more professional experience in data science.
- Find me on [GitHub](https://github.com/Fbehr-data), [LinkedIn](https://www.linkedin.com/in/felix-behrendt-3b4ba1237/)


Max Langer: 
- I am a biologist and highly motivated to build a career in data science.
- Find me on: [GitHub](https://github.com/langer-net), [LinkedIn](https://www.linkedin.com/in/max-langer-798903127/)

Picasso

Timo Fischer:

---
## Data Structure
For this project we use 6 of the 12 available spectral bands and the cloud mask of the Sentinel-2 data set. Information on the Sentinel-2 is available [here](https://de.wikipedia.org/wiki/Sentinel-2). 
- Each band consists of 2650 individual tiles (TIF-files), each with a size of 256 x 256 pixels, which corresponds to an area of 2560 m x 2560 m. 
- This means that we have all band information for each unique tile.
- Each of these unique tiles contains a certain amount of fields. 
- Each field has a unique ID and a unique label that identifies the crop type in the field. 

---
## Requirements and Setup:
### Requirements:

- [pyenv](https://github.com/pyenv/pyenv) with Python: 3.9.8
- [Poetry](https://python-poetry.org/): 1.1.13 or higher

### Setup

For setting up the `virtual environment` we used `Poetry`.
So after downloading the repository run the following code in your terminal:

```BASH
pyenv local 3.9.8
python -m venv .venv
source .venv/bin/activate
pip install --upgrade pip
poetry install
```

This will setup the virtual environment in a `.venv` folder and install all needed packages listed in the `pyproject.toml`. 

### Activate the environment

For activating your virtual environment when restarting the session use the following command:

```BASH
source .venv/bin/activate
```

---
## Downloading and Preprocessing the Data
### Downloading the data
The data is downloaded from the Radiant Earth Foundation servers. This requires the package `radiant-mlhub` in exactly `version 0.1.3`. This package should have already been installed by Poetry. Downloading and extracting may take a while (**about 2 - 5 hours**) depending on your internet connection.
You can start the download by typing the following in the terminal, while `being in the repository-folder`:

```BASH
python preprocessing.py download
```
### Preprocessing the data
The preprocessing scripts also take their time. In the `first preprocessing step`, we convert the image information from the TIF-files to NumPy arrays and save one array per field in the .npz format. This step takes another **1 - 3 hours** depending on the processor power in your PC. You can start the conversion by:

```BASH
python preprocessing.py convert
```

In the `second preprocessing step`, we calculate the mean of for each band of each field for each date. This results in a CSV-file that can be used for further feature engineering. The second preprocessing step is started by:

```BASH
python preprocessing.py download
```

---
## Feature engineering / Data cleaning, Train-Test-Split and Resampling
### Feature engineering / Data cleaning


```BASH
python feature_engineering.py
```

#### **cloud-masking**
For each tile and each timestamp a cloudmask (CLM) was provided. In case of clouds we don't measure field data, but the upper site of a cloud. To each field and timestamp the mode of cloudmask will be calculated and added to the data (during preprocessing). Thus results in two different values:
</br> 
* 0 - no cloud 
* 255 - no information

Currently our package provides two solution. The first option is to keep all the information delete all observations with no cloud information. See this [Notebook](https://github.com/Fbehr-data/Radiant-Earth-Spot-Crop/blob/main/notebooks/feature_engineering_01_cloudmask.ipynb) for more information. <br> 
#### **Spectral Indices**
In the field of remote sensing the actual bands are used to calculate spectral indices. These indices represent different information about the measured object. For example: The Normalized Difference Vegetation Index (NDVI) which is an indicator of the vitality of vegetation. A full list of indices can be found [here](https://www.indexdatabase.de/db/is.php?sensor_id=96). We calculate these indices based on the [EDA](https://github.com/Fbehr-data/Radiant-Earth-Spot-Crop/blob/main/notebooks/EDA_spectral_indices.ipynb).
- NDVI
- WET
- PVR 
- VARI_green
- MNSI
- NDRE
- GARI<br>

#### **Mean per Month and Feature-Time-Confusion** 
We calculate for each field the mean values of each feature and transform the the date column / months column and combine it to the features.

|Field ID | Month      | Feature     |
|-------- | -----------| ----------- | 
|1        | 4          | 0.4         |
|1        | 5          | 0.7         |

to


|Field ID | Feature of Month 4  | Feature of Month 5 |
|-------- | -----------| ----------- | 
|1        | 0.4        | 0.7         |

### Train-Test-Split
Splitting our dataset is essential for an unbiased evaluation of prediction performance. We randomly split our dataset into 3 subset:
- Training set : is applied to train, or fit, the model
- Validation set : is used for unbiased model evaluation during hyperparameter tuning
- Test set: is needed for an unbiased evaluation of the final model.
Now, in order to do that we need first to import the train_test_split function that we created, like this:
```BASH
from train_test_function import train_test_split_fields
```
the split is done by that function, we only set the train_size as the test_size will adjust accordingly. We also set the random_state to 42.

### Resampling
In the training set we have skewed class proportions. In order to solve the imbalanced classification problem, we are first going to combine class 8 and 9 into one class. Then we do the resampling using 2 techniques: downsampling the majority classes and upweighting the minority classes using RandomUnderSampler and RandomOverSampler from the imblearn library. For more details check Dataset in this [notebook](https://github.com/Fbehr-data/Radiant-Earth-Spot-Crop/blob/main/notebooks/Resampling_crop_type.ipynb).

---
## Results and Conclusion
### Evaluation metric
For the evaluation metric, we chose the `F1-score` as metric, since the main goal is to correctly identify the crop type of as many fields as possible. Neither false-positive (FP) nor false-negative (FN) miss-classifications are particularly good or bad, hence the harmonic mean F1. 

### Model performance
For the baseline model we chose a K-Nearest Neighbors (KNN) model, as this is a simple algorithm, which is based on the assumption that similar classes will be in close proximity of each other. It can be used for both binary and multiclass classifications and is very fast and easy to implement, especially for large data sets [source](https://towardsdatascience.com/multiclass-classification-using-k-nearest-neighbours-ca5281a9ef76). Decision tree ensemble methods were chosen for the more advanced models. They performed well compared to neural networks and KNN. For the F1 score, values of 0.42 were obtained for the baseline model (KNN) on the test data, while the [extremely randomized tree](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.ExtraTreesClassifier.html) and the [XGBClassifier](https://xgboost.readthedocs.io/en/stable/#) performed better with values between 0.59 and 0.61 on the test data. However, all models showed overfitting on the training data, implying that they could be further improved by more rigorous regularization.  Since the XGBClassifier performed best (highest F1 score and lower overfitting), the error analysis is performed using the results/predictions of this model.  

![F1-score](./plots/f1_models.png)

### Error analysis
When analyzing the errors of the XGBClassifier, we find no particularly striking misclassifications for particular classes. 